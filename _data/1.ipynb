{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import *\n",
    "from utils.flow import optical_flow\n",
    "from loguru import logger\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = Path(\"../_data\")\n",
    "video_folder = dataset_folder / \"video\"\n",
    "sub_video_folder = dataset_folder / \"sub_video\"\n",
    "sub_video_label_fodler = dataset_folder / \"sub_video_label\"\n",
    "\n",
    "sub_video_folder.mkdir(parents=True, exist_ok=True)\n",
    "sub_video_label_fodler.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_frames = 75\n",
    "width = 288\n",
    "height = 288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_list = sorted(list(video_folder.glob('*.mp4')), key=lambda x:x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyflow\n",
    "\n",
    "def optical_flow(src, tgt):\n",
    "    \"\"\"Optical flow from the source frame to each target frame using pyflow (https://github.com/pathak22/pyflow).\"\"\"\n",
    "    para = dict(alpha=0.012, ratio=0.75, minWidth=20, nOuterFPIterations=7, nInnerFPIterations=1, nSORIterations=30, colType=0)\n",
    "    \n",
    "    assert src.dtype == np.uint8 and len(src.shape) == 3, src.shape\n",
    "    assert tgt.dtype == np.uint8 and len(tgt.shape) in [3, 4], tgt.shape\n",
    "    assert tgt.shape[-3:] == src.shape, (src.shape, tgt.shape)\n",
    "    \n",
    "    src = src.astype(float) / 255\n",
    "    tgt = tgt.astype(float) / 255\n",
    "    \n",
    "    if len(tgt.shape) == 3:\n",
    "        *uv, _ = pyflow.coarse2fine_flow(src, tgt, **para)\n",
    "        return np.stack(uv, axis=2)\n",
    "    else:\n",
    "        flow = []\n",
    "        for im in tgt:\n",
    "            *uv, _ = pyflow.coarse2fine_flow(src, im, **para)\n",
    "            flow.append(np.stack(uv, axis=2))\n",
    "        return np.stack(flow)\n",
    "\n",
    "def get_frames(inp: str, w: int, h: int, start_sec: float = 0, t: float = None, f: int = None, fps = None,) -> np.ndarray:\n",
    "    args = []\n",
    "    if t is not None:\n",
    "        args += [\"-t\", f\"{t:.2f}\"]\n",
    "    elif f is not None:\n",
    "        args += [\"-frames:v\", str(f)]\n",
    "    if fps is not None:\n",
    "        args += [\"-r\", str(fps)]\n",
    "    \n",
    "    args = [\"ffmpeg\", \"-nostdin\", \"-ss\", f\"{start_sec:.2f}\", \"-i\", inp, *args, \n",
    "        \"-f\", \"rawvideo\", \"-pix_fmt\", \"rgb24\", \"-s\", f\"{w}x{h}\", \"pipe:\"]\n",
    "    \n",
    "    process = subprocess.Popen(args, stderr=-1, stdout=-1)\n",
    "    out, err = process.communicate()\n",
    "    retcode = process.poll()\n",
    "    if retcode:\n",
    "        raise Exception(f\"{inp}: ffmpeg error: {err.decode('utf-8')}\")\n",
    "\n",
    "    return np.frombuffer(out, np.uint8).reshape(-1, h, w, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-23 20:10:56.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1m..\\_data\\video\\0001.mp4 0 (75, 288, 288, 3)\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m         writer\u001b[38;5;241m.\u001b[39mappend_data(frame)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# np.save(sub_video_folder / f'{video_file.stem}_{sub_video_start_time}_{num_frames}_{video_fps}.npy', frames)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m flow \u001b[38;5;241m=\u001b[39m \u001b[43moptical_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     20\u001b[0m np\u001b[38;5;241m.\u001b[39msave(sub_video_label_fodler \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_file\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub_video_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_frames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_fps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, flow\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat16))\n",
      "Cell \u001b[1;32mIn[4], line 21\u001b[0m, in \u001b[0;36moptical_flow\u001b[1;34m(src, tgt)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im \u001b[38;5;129;01min\u001b[39;00m tgt:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39muv, _ \u001b[38;5;241m=\u001b[39m pyflow\u001b[38;5;241m.\u001b[39mcoarse2fine_flow(src, im, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpara)\n\u001b[1;32m---> 21\u001b[0m     flow\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43muv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(flow)\n",
      "File \u001b[1;32mc:\\Users\\lolikonloli\\.conda\\envs\\tc241\\lib\\site-packages\\numpy\\core\\shape_base.py:362\u001b[0m, in \u001b[0;36m_stack_dispatcher\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m--> 362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stack_dispatcher\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    363\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    364\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m _arrays_for_stack_dispatcher(arrays)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;66;03m# optimize for the typical case where only arrays is provided\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for video_file in video_file_list:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    video_frame_num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    if video_fps in [23, 29]:\n",
    "        video_fps += 1\n",
    "\n",
    "    for sub_frame_idx in range(video_frame_num // num_frames):\n",
    "        sub_video_start_time = sub_frame_idx*(num_frames/video_fps)\n",
    "        \n",
    "        frames = get_frames(video_file, w=width, h=height, start_sec=sub_video_start_time, fps=video_fps, f=num_frames)\n",
    "        logger.info(f'{video_file} {sub_frame_idx} {frames.shape}')\n",
    "        \n",
    "        with imageio.get_writer(sub_video_folder / f'{video_file.stem}_{sub_video_start_time}_{num_frames}_{video_fps}.mp4', fps=video_fps) as writer:\n",
    "            for frame in frames:\n",
    "                writer.append_data(frame)\n",
    "        # np.save(sub_video_folder / f'{video_file.stem}_{sub_video_start_time}_{num_frames}_{video_fps}.npy', frames)\n",
    "        flow = optical_flow(frames[0], frames[1:])\n",
    "        break\n",
    "        np.save(sub_video_label_fodler / f'{video_file.stem}_{sub_video_start_time}_{num_frames}_{video_fps}.npy', flow.astype(np.float16))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试代码段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # type: ignore\n",
    "\n",
    "a = np.load('../_data/sub_video_label/0001_3.0_75_25.npy')\n",
    "b = np.load('../_data/flow/0001_003.npy')\n",
    "np.array_equal(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc241",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
